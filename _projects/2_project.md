---
layout: page
title: Radar Mapping and Navigation
description: 
img: assets/img/Overview.png
importance: 1
category: work
---

Although Lidar and Camera sensors provide dense, reliable data about the 3D environments, they are severly affected in visually degraded environments like fog, smoke, rain, snow etc. Radar sensors are a promising alternative because they are unaffected in these harsh environments. However, the maps generated from the sparse and noisy radar measurements have high amounts of noise, missing regions, and are of low resolution compared to the maps generated by the lidar. The standalone radar data can't be directly used in navigation and mapping, unless aided by advanced deep learning techniques. 

To address these issues, we developed :
1. A generative transformer architecture, UpPoinTr, which can interpret noisy, low-res and incomplete pointcloud to a navigable map.
2. Pose-based region sampling alï¿¾gorithm, which effectively represents the 3D maps as partial point clouds
2. Dataset with 3D radar maps and groundruth lidar maps 

System Diagram:
<div class="row">
    <div class="col-sm mt-md-0">
        {% include figure.html path="assets/img/RMap_Overview.png" title="Architecture" class="img-fluid rounded z-depth-1" %}
    </div>
</div>


Demo: 
<div class="row">
    <div class="caption">
        {% include video.html path="assets/video/RMap.mp4" class="img-fluid rounded z-depth-1" controls=true autoplay=true %}
    </div>
</div>
