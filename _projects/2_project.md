---
layout: page
title: Radar Mapping and Navigation
description: 
img: assets/img/14.jpg
importance: 1
category: work
---

Although Lidar and Camera sensors provide dense, reliable data about the 3D environments, they are severly affected in visually degraded environments like fog, smoke, rain, snow etc. Radar sensors are a promising alternative because they are unaffected in these harsh environments. However, the maps generated from the sparse and noisy radar measurements have high amounts of noise, missing regions, and are of low resolution compared to the maps generated by the lidar. The standalone radar data can't be directly used in navigation and mapping, unless aided by advanced deep learning techniques. 

To address these issues, we developed :
1. A generative transformer architecture which can interpret noisy, low-res and incomplete pointcloud to a navigable map.
2. Dataset which partial radar maps and groundruth lidar maps
3. Pose sampling to effectively represent large number of points, required for a map in the environment. Our pose sampling captures 99.99% of the data, compared to 80% data captured using random sampling.
4. A navigation metric, using the state-of-the-art path planners, to assess the quality of generated radar maps in navigation. 


<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/Radar.png" title="Radar Input Map" caption="Radar Input Map" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/Radar_reconstructed.png" title="Radar Reconstructed Map" caption="Radar Reconstructed Map" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/Lidar.png" title="Lidar GT Map" caption="Lidar GT Map" class="img-fluid rounded z-depth-1" %}
    </div>
</div>