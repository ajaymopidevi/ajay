- title: General Information
  type: map
  contents:
    - name: Full Name
      value: Ajay Narasimha Mopidevi
    - name : Email
      value: ajay.mopidevi@colorado.edu
   
- title: Education
  type: time_table
  contents:
    - title: Masters of Science in Computer Science  (CGPA - 4.0 / 4.0)
      institution: University of Colorado Boulder
      year: 2022 - 2023
      CGPA : 4.0 / 4.0
    - title: Bachelors of Technology in Electronics and Communication Engineering 
      institution: Indian Institute of Technology (IIT) Guwahati, India
      year: 2013 - 2017
      

- title: Publications
  type: time_table
  contents:
    - title: <a href="https://arxiv.org/pdf/2306.09523.pdf"> Tell Me Where to Go A Composable Framework for Context-Aware Embodied Robot Navigation</a>
    - title: A Multi-Agent Framework for Landmark-Guided Language-Based Navigation
    - title: <a href="https://aclanthology.org/2023.semeval-1.222">Grouped BERT for Multi-Label classification to reason the human values behind the arguments </a>

- title: Skills
  type: map
  contents:
    - name: Language
      value: Python, C/C++, Matlab
    - name : Machine Learning Frameworks
      value: Pytorch, Tensorflow, Keras
    - name: Libraries
      value: OpenCV, ROS, Open3D, pcl, pandas, NumPy, scikit-learn, scipy, Matplotlib
    - name: Tools
      value: Git,  Visual Studio, PyCharm, Eclipse, IntelliJ, Meshlab, CloudCompare
    
- title: Experience
  type: time_table
  contents:
    - title: Research Assistant 
      institution: <a href="https://arpg.github.io/">Autonomous Robotics and Perception Group</a>
      year: Sep 2022 - Present
      description:
        - Designed NavCon, a low bandwidth robot navigation framework using Large Language Models(<b>LLM</b>s), achieving a 71.3% success rate in guiding a <b>Spot</b> robot through intricate human commands in various environments
        - Utilized only the radar data, sparse pointclouds compared to Lidar data, to overcome the challenges in visually degraded scenarios and improved the odometry estimation by 8% , using transformer and DeepVO architectures
        - Developed generative transformer architecture for denoising radar pointclouds and generating the incomplete sections in them. Used transformed pointclouds to provide more spatial information in localization and mapping
    - title: Research Assistant 
      institution: <a href="http://cryoem.colorado.edu/">Vignesh Kasinath Lab</a>
      year: Apr 2023 - Present
      description:
        - Achieved 92% accuracy in segmenting cellular structures like ribosomes and membranes using 1 % of the entire tomogram for training
        - Designed U-NeXt architectures, combining the ConvNeXt and U-Net, specifically tailored for tomograms captured at different scales, resulting in a f1 score of 85% for segmentation
    - title: Computer Vision Research Engineer 
      institution: Samsung Semiconductord India R&D
      year: Jul 2020 - Jul 2022
      description:
        - Developed <b>3D scene reconstruction</b> algorithm, exclusively leveraging depth from ToF sensors, achieving a real-time processing speed of <b>20fps</b>
        - Improved the <b>accuracy by 5%</b> by detecting and removing outliers and also automated the pose alignment of output 3D scene with groundtruth to eliminate the manual alignment in MeshLab
        - Reduced the latency of Remosaic deep learning models for 200M pixel camera sensor using quantization and pruning techniques by 10 % with an unnoticeable degradation of 0.1% in perceptual quality
        - Optimized Samsung’s CMOS camera sensor noise reduction algorithm with OpenMP parallel programming, thereby reducing the algorithm runtime by 33%
    - title: Software Engineer
      institution: Qualcomm
      year: Aug 2017 - Jun 2020
      description:
        - Spearheaded the development and maintenance of python audio library to evaluate both the objective and perceptual audio quality of the Bluetooth headsets
        - Enhanced python automated test framework with new features that populate test vectors and visualize audio output signals, leading to a 10%-15% reduction in both the validation and development teams’ efforts
    - title: Research Intern
      institution: <a href="https://www.uncannyvision.com/">Eagle Eye Networks</a> 
      year: May 2017 - Jul 2017
      description:
        - Leveraged YOLO for object localization, optical flow for trajectory estimation, achieving 83% accuracy in detecting location and trajectory anomalies through Incremental Spherical Clustering and frequency heatmap


- title: Awards
  type: time_table
  contents:
    - year: 2022
      items:
        - Received Employer of the Month at Samsung, for successfully optimizing the noise reduction algorithm to reduce runtime by 33%
    - year: 2020
      items: 
        -  Received the Spot Appreciation award, for exceptional performance in delivering the 3D reconstruction pipeline for Samsung's ToF sensors
    - year: 2019
      items: 
        - Received Qualstar from Qualcomm for continued excellence in improving the audio quality analysis framework 
    

- title: Courses
  type: nested_list
  contents:
    - items: 
        -   Advanced Topics in Computer Vision
        -   Deep Reinforcement Learning
        -   Natural Language Processing
        -   Advanced Topics in Machine Learning
        -   Advanced Robotics
        -   Computer Vision 
        -   Computational Photography
        -   Computer Graphics
        -   Sensor Fusion
        
        